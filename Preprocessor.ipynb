{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"NOLA Restaurants.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\yahms\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\yahms\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\omw-1.4.zip.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "  \n",
    "\n",
    "'''\n",
    "Preprocess a string.\n",
    ":parameter\n",
    "    :param text: string - name of column containing text\n",
    "    :param lst_stopwords: list - list of stopwords to remove\n",
    "    :param flg_lemm: bool - whether lemmitisation is to be applied\n",
    ":return\n",
    "    cleaned text\n",
    "'''\n",
    "def utils_preprocess_text(text, flg_lemm=True, lst_stopwords=None):\n",
    "    ## clean (convert to lowercase and remove punctuations and  characters and then strip)\n",
    "    text = re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "            \n",
    "    ## Tokenize (convert from string to list)\n",
    "    lst_text = text.split()    ## remove Stopwords\n",
    "    if lst_stopwords is not None:\n",
    "        lst_text = [word for word in lst_text if word not in \n",
    "                    lst_stopwords]\n",
    "                \n",
    "                \n",
    "    ## Lemmatisation (convert the word into root word)\n",
    "    if flg_lemm == True:\n",
    "        lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "        lst_text = [lem.lemmatize(word) for word in lst_text]\n",
    "            \n",
    "    ## back to string from list\n",
    "    text = \" \".join(lst_text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>review_count</th>\n",
       "      <th>avg_stars</th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>stars</th>\n",
       "      <th>wordcount</th>\n",
       "      <th>train</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YNjyv0gfOr2g8lbmUpTnKg</td>\n",
       "      <td>Copper Vine</td>\n",
       "      <td>350</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2u8kIWm1CrMGuwGTW1HBGQ</td>\n",
       "      <td>nn6DoANEtr7SgvWWgrh2oQ</td>\n",
       "      <td>The service is awesome...staff is very friendl...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>service awesomestaff friendly knowledgeable go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YNjyv0gfOr2g8lbmUpTnKg</td>\n",
       "      <td>Copper Vine</td>\n",
       "      <td>350</td>\n",
       "      <td>4.5</td>\n",
       "      <td>EwarwhOOmnB22qESUv_VPw</td>\n",
       "      <td>G6ZnatT96yzdcX81PZyT3g</td>\n",
       "      <td>New and cool spot in downtown New Orleans!\\nGr...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>51</td>\n",
       "      <td>False</td>\n",
       "      <td>new cool spot downtown new orleans great varie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>YNjyv0gfOr2g8lbmUpTnKg</td>\n",
       "      <td>Copper Vine</td>\n",
       "      <td>350</td>\n",
       "      <td>4.5</td>\n",
       "      <td>EdsUPECvSzIj503qt13Pwg</td>\n",
       "      <td>dRvKAgf9a0DSKioJSv1p0Q</td>\n",
       "      <td>We went here before a concert. It was super bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>went concert super busy service sort slow lot ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YNjyv0gfOr2g8lbmUpTnKg</td>\n",
       "      <td>Copper Vine</td>\n",
       "      <td>350</td>\n",
       "      <td>4.5</td>\n",
       "      <td>XEfHuaszNLgeUu-6gXB-qQ</td>\n",
       "      <td>JDOeSXX33nUx4q-AmUFBSw</td>\n",
       "      <td>My friends and I had a great meal at Copper Vi...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>177</td>\n",
       "      <td>True</td>\n",
       "      <td>friend great meal copper vine space beautifull...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>YNjyv0gfOr2g8lbmUpTnKg</td>\n",
       "      <td>Copper Vine</td>\n",
       "      <td>350</td>\n",
       "      <td>4.5</td>\n",
       "      <td>W7_4Dd6xTuWuTDqe68XBtQ</td>\n",
       "      <td>GCldu8eAzez5rSFpijNZ3A</td>\n",
       "      <td>What a great concept! 38 wines on tap, oh yeah...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>65</td>\n",
       "      <td>True</td>\n",
       "      <td>great concept 38 wine tap oh yeah fantastic sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>YNjyv0gfOr2g8lbmUpTnKg</td>\n",
       "      <td>Copper Vine</td>\n",
       "      <td>350</td>\n",
       "      <td>4.5</td>\n",
       "      <td>iFSgljVogeJYq44jppE2zQ</td>\n",
       "      <td>ScskFjiX1EwhJritfYHPuQ</td>\n",
       "      <td>Our waitress Rose was amazing. Made me feel li...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>True</td>\n",
       "      <td>waitress rose amazing made feel like home bar ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>YNjyv0gfOr2g8lbmUpTnKg</td>\n",
       "      <td>Copper Vine</td>\n",
       "      <td>350</td>\n",
       "      <td>4.5</td>\n",
       "      <td>PEVRSj1KilCMmxw0l1at1A</td>\n",
       "      <td>4HTjgdTXIK07za49VvfF7A</td>\n",
       "      <td>Best place in the CBD. Rolled in rough around ...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>True</td>\n",
       "      <td>best place cbd rolled rough around edge rose s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>YNjyv0gfOr2g8lbmUpTnKg</td>\n",
       "      <td>Copper Vine</td>\n",
       "      <td>350</td>\n",
       "      <td>4.5</td>\n",
       "      <td>b4IUHT-DvIeEneCNx7O0jA</td>\n",
       "      <td>eUVmYjvgSPTojgff5CToXg</td>\n",
       "      <td>So the waiter was great, the atmosphere was GR...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>132</td>\n",
       "      <td>False</td>\n",
       "      <td>waiter great atmosphere great red blend copper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>YNjyv0gfOr2g8lbmUpTnKg</td>\n",
       "      <td>Copper Vine</td>\n",
       "      <td>350</td>\n",
       "      <td>4.5</td>\n",
       "      <td>dx_dmJDhUrQJ16-Oqp73Eg</td>\n",
       "      <td>FbQiilAZrTValxD_X3cPZw</td>\n",
       "      <td>I have been here twice, and will continue to c...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>242</td>\n",
       "      <td>False</td>\n",
       "      <td>twice continue come perfect setting instagramw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>YNjyv0gfOr2g8lbmUpTnKg</td>\n",
       "      <td>Copper Vine</td>\n",
       "      <td>350</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Qekf7LisFJNPn6aFzKB-Jg</td>\n",
       "      <td>BqAu7D5qHMQsrlRW8bRl-w</td>\n",
       "      <td>My sister and I ate here last Sunday and it wa...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>37</td>\n",
       "      <td>True</td>\n",
       "      <td>sister ate last sunday beyond amazing atmosphe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id         name  review_count  avg_stars  \\\n",
       "0  YNjyv0gfOr2g8lbmUpTnKg  Copper Vine           350        4.5   \n",
       "1  YNjyv0gfOr2g8lbmUpTnKg  Copper Vine           350        4.5   \n",
       "2  YNjyv0gfOr2g8lbmUpTnKg  Copper Vine           350        4.5   \n",
       "3  YNjyv0gfOr2g8lbmUpTnKg  Copper Vine           350        4.5   \n",
       "4  YNjyv0gfOr2g8lbmUpTnKg  Copper Vine           350        4.5   \n",
       "5  YNjyv0gfOr2g8lbmUpTnKg  Copper Vine           350        4.5   \n",
       "6  YNjyv0gfOr2g8lbmUpTnKg  Copper Vine           350        4.5   \n",
       "7  YNjyv0gfOr2g8lbmUpTnKg  Copper Vine           350        4.5   \n",
       "8  YNjyv0gfOr2g8lbmUpTnKg  Copper Vine           350        4.5   \n",
       "9  YNjyv0gfOr2g8lbmUpTnKg  Copper Vine           350        4.5   \n",
       "\n",
       "                review_id                 user_id  \\\n",
       "0  2u8kIWm1CrMGuwGTW1HBGQ  nn6DoANEtr7SgvWWgrh2oQ   \n",
       "1  EwarwhOOmnB22qESUv_VPw  G6ZnatT96yzdcX81PZyT3g   \n",
       "2  EdsUPECvSzIj503qt13Pwg  dRvKAgf9a0DSKioJSv1p0Q   \n",
       "3  XEfHuaszNLgeUu-6gXB-qQ  JDOeSXX33nUx4q-AmUFBSw   \n",
       "4  W7_4Dd6xTuWuTDqe68XBtQ  GCldu8eAzez5rSFpijNZ3A   \n",
       "5  iFSgljVogeJYq44jppE2zQ  ScskFjiX1EwhJritfYHPuQ   \n",
       "6  PEVRSj1KilCMmxw0l1at1A  4HTjgdTXIK07za49VvfF7A   \n",
       "7  b4IUHT-DvIeEneCNx7O0jA  eUVmYjvgSPTojgff5CToXg   \n",
       "8  dx_dmJDhUrQJ16-Oqp73Eg  FbQiilAZrTValxD_X3cPZw   \n",
       "9  Qekf7LisFJNPn6aFzKB-Jg  BqAu7D5qHMQsrlRW8bRl-w   \n",
       "\n",
       "                                                text  useful  stars  \\\n",
       "0  The service is awesome...staff is very friendl...       0      5   \n",
       "1  New and cool spot in downtown New Orleans!\\nGr...       0      5   \n",
       "2  We went here before a concert. It was super bu...       0      4   \n",
       "3  My friends and I had a great meal at Copper Vi...       0      4   \n",
       "4  What a great concept! 38 wines on tap, oh yeah...       1      5   \n",
       "5  Our waitress Rose was amazing. Made me feel li...       0      5   \n",
       "6  Best place in the CBD. Rolled in rough around ...       0      5   \n",
       "7  So the waiter was great, the atmosphere was GR...       1      4   \n",
       "8  I have been here twice, and will continue to c...       1      5   \n",
       "9  My sister and I ate here last Sunday and it wa...       0      5   \n",
       "\n",
       "   wordcount  train                                         text_clean  \n",
       "0         32   True  service awesomestaff friendly knowledgeable go...  \n",
       "1         51  False  new cool spot downtown new orleans great varie...  \n",
       "2         60  False  went concert super busy service sort slow lot ...  \n",
       "3        177   True  friend great meal copper vine space beautifull...  \n",
       "4         65   True  great concept 38 wine tap oh yeah fantastic sp...  \n",
       "5         18   True  waitress rose amazing made feel like home bar ...  \n",
       "6         52   True  best place cbd rolled rough around edge rose s...  \n",
       "7        132  False  waiter great atmosphere great red blend copper...  \n",
       "8        242  False  twice continue come perfect setting instagramw...  \n",
       "9         37   True  sister ate last sunday beyond amazing atmosphe...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STOPWORDS = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "data[\"text_clean\"] = data[\"text\"].apply(lambda x: \n",
    "          utils_preprocess_text(x, flg_lemm=True, \n",
    "          lst_stopwords=STOPWORDS))\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = data[data['train']== True]\n",
    "Test = data[data['train']== False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150845"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(num_words = 3000, oov_token = '<OOV>', split=' ')\n",
    "tokenizer.fit_on_texts(Train['text_clean'])\n",
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12830"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([t for t in tokenizer.word_counts.values() if int(t) >= 25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = 12000, oov_token = '<OOV>', split=' ')\n",
    "tokenizer.fit_on_texts(Train['text_clean'])\n",
    "X_train = tokenizer.texts_to_sequences(Train['text_clean'])\n",
    "X_train = pad_sequences(X_train, padding=\"pre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = tokenizer.texts_to_sequences(Test['text_clean'])\n",
    "X_test = pad_sequences(X_test, maxlen = X_train.shape[1], padding=\"pre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = Test['stars']\n",
    "Y_train = Train['stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 150845 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're using GloVe's twitter vectors, as they may match up better with yelp slang.\n",
    "# https://nlp.stanford.edu/projects/glove/ (download here!)\n",
    "The max dimensionality of the embedded vectors is 200-dimensional, which we;ll try to use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1193514 word vectors.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open('glove.twitter.27B.200d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((12001, 200))\n",
    "for word, i in word_index.items():\n",
    "    if i > 12000:\n",
    "        break\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, Input\n",
    "\n",
    "embedding_layer = Embedding(12001,\n",
    "                            200,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=237,\n",
    "                            trainable=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 237, 200)          2400200   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 237, 200)          0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 196)               311248    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 985       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,712,433\n",
      "Trainable params: 312,233\n",
      "Non-trainable params: 2,400,200\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "\n",
    "lstm_out = 196\n",
    "batch_size = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(lstm_out, dropout = 0.2))\n",
    "model.add(Dense(5,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = pd.get_dummies(Y_train)\n",
    "Y_test = pd.get_dummies(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(file=\"X_test.npy\",arr=X_test)\n",
    "np.save(file=\"X_train.npy\",arr=X_train)\n",
    "np.save(file=\"Y_test.npy\",arr=Y_test)\n",
    "np.save(file=\"Y_train.npy\",arr=Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445947</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445948</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445950</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445951</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445952</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>334466 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1  2  3  4  5\n",
       "0       0  0  0  0  1\n",
       "3       0  0  0  1  0\n",
       "4       0  0  0  0  1\n",
       "5       0  0  0  0  1\n",
       "6       0  0  0  0  1\n",
       "...    .. .. .. .. ..\n",
       "445947  0  0  0  1  0\n",
       "445948  0  0  0  0  1\n",
       "445950  0  1  0  0  0\n",
       "445951  0  0  0  0  1\n",
       "445952  0  1  0  0  0\n",
       "\n",
       "[334466 rows x 5 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10453/10453 [==============================] - 219s 21ms/step - loss: 0.7574 - accuracy: 0.6715\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid keyword arguments: ['epochs']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\yahms\\OneDrive\\Documents\\ML_Project\\Bus-ML\\Preprocessor.ipynb Cell 17'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yahms/OneDrive/Documents/ML_Project/Bus-ML/Preprocessor.ipynb#ch0000020?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39mfit(X_train, Y_train, batch_size \u001b[39m=\u001b[39m batch_size, verbose \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/yahms/OneDrive/Documents/ML_Project/Bus-ML/Preprocessor.ipynb#ch0000020?line=3'>4</a>\u001b[0m score,acc \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mevaluate(X_test, Y_test, verbose \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m, batch_size \u001b[39m=\u001b[39;49m batch_size, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yahms/OneDrive/Documents/ML_Project/Bus-ML/Preprocessor.ipynb#ch0000020?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mScore: \u001b[39m\u001b[39m%.2f\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (score))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yahms/OneDrive/Documents/ML_Project/Bus-ML/Preprocessor.ipynb#ch0000020?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mValidation Accuracy: \u001b[39m\u001b[39m%.2f\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (acc))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/yahms/anaconda3/envs/tf_gpu/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/yahms/anaconda3/envs/tf_gpu/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> <a href='file:///c%3A/Users/yahms/anaconda3/envs/tf_gpu/lib/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     <a href='file:///c%3A/Users/yahms/anaconda3/envs/tf_gpu/lib/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/yahms/anaconda3/envs/tf_gpu/lib/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py:1668\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/yahms/anaconda3/envs/tf_gpu/lib/site-packages/keras/engine/training.py?line=1665'>1666</a>\u001b[0m use_cached_eval_dataset \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39m_use_cached_eval_dataset\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   <a href='file:///c%3A/Users/yahms/anaconda3/envs/tf_gpu/lib/site-packages/keras/engine/training.py?line=1666'>1667</a>\u001b[0m \u001b[39mif\u001b[39;00m kwargs:\n\u001b[1;32m-> <a href='file:///c%3A/Users/yahms/anaconda3/envs/tf_gpu/lib/site-packages/keras/engine/training.py?line=1667'>1668</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInvalid keyword arguments: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(kwargs\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m   <a href='file:///c%3A/Users/yahms/anaconda3/envs/tf_gpu/lib/site-packages/keras/engine/training.py?line=1669'>1670</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy\u001b[39m.\u001b[39m_should_use_with_coordinator:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/yahms/anaconda3/envs/tf_gpu/lib/site-packages/keras/engine/training.py?line=1670'>1671</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cluster_coordinator \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mcoordinator\u001b[39m.\u001b[39mClusterCoordinator(\n\u001b[0;32m   <a href='file:///c%3A/Users/yahms/anaconda3/envs/tf_gpu/lib/site-packages/keras/engine/training.py?line=1671'>1672</a>\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy)\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid keyword arguments: ['epochs']"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size = batch_size, verbose = 1)\n",
    "\n",
    "\n",
    "score,acc = model.evaluate(X_test, Y_test, verbose = 1, batch_size = batch_size, epochs=10)\n",
    "print(\"Score: %.2f\" % (score))\n",
    "print(\"Validation Accuracy: %.2f\" % (acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "334466"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "be24bb95faf61c32e80f49cbe1f3e5c81fc006a140d445a9e7b10e4ad101affd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tf_gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
